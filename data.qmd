---
title: Data
description: We describe the sources of our data and the cleaning process.
toc: true
draft: false
---

![](images/doe_ma415.webp)


This comes from the file `data.qmd`.

## Data Overview

The data was originally collected and compiled by the U.S. Department of Education to provide transparency and consumer information related to individual institutions of higher education and individual fields of study within those institutions. The dataset includes data from the 1996-97 academic year to the 2022-23 academic year. 

The data was initiated under President Obama's administration to ensure reliable information exists to help students find colleges that best fit their needs, enabling them to succeed. The dataset can be accessed using this [link](https://collegescorecard.ed.gov/data/). 

### Limitations of the Data
- It is an extremely large dataset consisting of over 3,000 variables/columns, requiring significant cleaning.  
- The sample focuses only on Title IV institutions, meaning schools not participating in federal aid programs may be excluded, potentially introducing bias.


## Data Files and Variables

Some of the most important variables we looked at include:

- Race  
- Withdrawal Rates & Completion Rates  
- Financial Aid/Pell Grants  
- Family Income  
- Debt/Loans  
- Earnings Post-Graduation  
- Test Scores  

 
## Data Cleaning

We cleaned the data by manually going through the dataset and selecting variables that are relevant to our study. We were guided by information that may help highlight racial inequalities within the U.S.'s post-secondary education system. These variables were then saved to a CSV file, and a new dataset containing only the relevant variables was created. The cleaned dataset contains 316 columns. 

```{r}
#| warning: false
#| message: false
#| echo: true
#| results: "hide"

library(tidyverse)

# Read in the datasets
data = read_csv("dataset/dataset-ignore/Most-Recent-Cohorts-Institution.csv")
data_cols = read_csv("dataset/cleaned_dataset.csv") # Most important variables from the dataset

data_cols <- data_cols |> 
  filter(!is.na(Variable)) # Make sure there aren't any null values

# Select the columns listed in data_cols$Variable
cleaned_data <- data |>
  select(all_of(data_cols$Variable))

write_rds(cleaned_data, file = here::here("dataset", "cleaned_dataset.rds"))

read_rds("dataset/cleaned_dataset.rds")
```


----

## Rubric: On this page

You will

* Describe where/how to find data.
  * You must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.
  * Why was the data collected/curated? Who put it together? (This is important, if you don't know why it was collected then that might not be a good dataset to look at.
* Describe the different data files used and what each variable means. 
  * If you have many variables then only describe the most relevant ones and summarize the rest.
* Describe any cleaning you had to do for your data.
  * You *must* include a link to your `load_and_clean_data.R` file.
  * Rrename variables and recode factors to make data more clear.
  * Also, describe any additional R packages you used outside of those covered in class.
  * Describe and show code for how you combined multiple data files and any cleaning that was necessary for that.
  * Some repetition of what you do in your `load_and_clean_data.R` file is fine and encouraged if it helps explain what you did.
* Organization, clarity, cleanliness of the page
  * Make sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.
  * This page should be self-contained.